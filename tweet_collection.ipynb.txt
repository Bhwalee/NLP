{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tweet Collection Process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import the usual suspects\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test the pipeline\n",
    "from pipeline import NLPPipe, tweet_clean1\n",
    "\n",
    "# Turn the JSON data into a DataFrame\n",
    "from helper_functions import txt_to_df, display_topics, scatter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "The code below might seem a little messy, but I kept learning every time I scraped more tweets, thus the large number of .txt files. With my current understanding of SNSCRAPE, I could reduce the number of files dramatically in the future."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets2 = txt_to_df('Data/twitter_data2.txt')\n",
    "tweets3 = txt_to_df('Data/twitter_data3.txt')\n",
    "tweets4 = txt_to_df('Data/twitter_data4.txt')\n",
    "tweets5 = txt_to_df('Data/twitter_data5.txt')\n",
    "tweets6 = txt_to_df('Data/twitter_data6.txt')\n",
    "tweets7 = txt_to_df('Data/twitter_data7.txt')\n",
    "tw2015 = txt_to_df('Data/tw2015.txt')\n",
    "tw2016 = txt_to_df('Data/tw2016.txt')\n",
    "tw2017 = txt_to_df('Data/tw2017.txt')\n",
    "tw2018 = txt_to_df('Data/tw2018.txt')\n",
    "tw2019 = txt_to_df('Data/tw2019.txt')\n",
    "tw2020 = txt_to_df('Data/tw2020.txt')\n",
    "t2w2015 = txt_to_df('Data/t2w2015.txt')\n",
    "t2w2016 = txt_to_df('Data/t2w2016.txt')\n",
    "t2w2017 = txt_to_df('Data/t2w2017.txt')\n",
    "t2w2018 = txt_to_df('Data/t2w2018.txt')\n",
    "t2w2019 = txt_to_df('Data/t2w2019.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all of the DataFrames into the full Tweet corpus\n",
    "all_tweets = pd.concat([tweets2, tweets3, tweets4, tweets5, tweets6, tweets7,tw2015,tw2016,tw2017,tw2018,tw2019,tw2020,t2w2015,t2w2016,t2w2017,t2w2018,t2w2019])\n",
    "all_tweets = all_tweets.drop_duplicates().reset_index()\n",
    "all_tweets.drop(labels='index',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets.to_pickle(\"tweets_year2.pkl\")\n",
    "# Now we save this DataFrame for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               long_text  year\n",
       "0      RT @ForksOverKnives: Fall colors shine through...  2020\n",
       "1      Risotto, daal, pasta bake with herbs, a pumpki...  2020\n",
       "2      @queennjemima You say that now but thereâ€™s a l...  2020\n",
       "3                                            Good read    2020\n",
       "4      RT @Fiorella_im: BREAKING according to judge, ...  2020\n",
       "...                                                  ...   ...\n",
       "58477  Instagramâ€™s Official Account Promotes ðŸŒ± Activi...  2019\n",
       "58478  Chillinâ€™ the fuck out! @sundayscaries #sundays...  2019\n",
       "58479  Made this tonight to go with a new EASY #recip...  2019\n",
       "58480  #Repost kashiwaramen with get_repost\\nãƒ»ãƒ»ãƒ»\\nLoo...  2019\n",
       "58481  I was never a big fan of Tofu, but when done r...  2019\n",
       "\n",
       "[58482 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>long_text</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RT @ForksOverKnives: Fall colors shine through...</td>\n      <td>2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Risotto, daal, pasta bake with herbs, a pumpki...</td>\n      <td>2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@queennjemima You say that now but thereâ€™s a l...</td>\n      <td>2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good read</td>\n      <td>2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @Fiorella_im: BREAKING according to judge, ...</td>\n      <td>2020</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58477</th>\n      <td>Instagramâ€™s Official Account Promotes ðŸŒ± Activi...</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>58478</th>\n      <td>Chillinâ€™ the fuck out! @sundayscaries #sundays...</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>58479</th>\n      <td>Made this tonight to go with a new EASY #recip...</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>58480</th>\n      <td>#Repost kashiwaramen with get_repost\\nãƒ»ãƒ»ãƒ»\\nLoo...</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>58481</th>\n      <td>I was never a big fan of Tofu, but when done r...</td>\n      <td>2019</td>\n    </tr>\n  </tbody>\n</table>\n<p>58482 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "all_tweets"
   ]
  }
 ]
}